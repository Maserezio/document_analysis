{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-22T23:31:42.356980Z",
     "start_time": "2024-04-22T23:31:40.172168Z"
    }
   },
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "12.1\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T23:31:43.873294Z",
     "start_time": "2024-04-22T23:31:43.672476Z"
    }
   },
   "cell_type": "code",
   "source": "!nvidia-smi",
   "id": "7569873658e67f8a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Apr 23 01:31:43 2024       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 535.171.04             Driver Version: 535.171.04   CUDA Version: 12.2     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce RTX 3070 ...    Off | 00000000:01:00.0 Off |                  N/A |\r\n",
      "| N/A   42C    P0              29W / 115W |     11MiB /  8192MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|    0   N/A  N/A      1641      G   /usr/lib/xorg/Xorg                            4MiB |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T20:30:42.820475Z",
     "start_time": "2024-04-24T20:30:42.811982Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import doxapy\n",
    "from tabulate import tabulate\n",
    "\n",
    "def evaluate(gt_imgs, pr_imgs, print_results=True):\n",
    "    perf_data = []\n",
    "\n",
    "    for gt_img, pr_img in zip(gt_imgs, pr_imgs):\n",
    "        perf_data.append(doxapy.calculate_performance(gt_img, pr_img))\n",
    "\n",
    "    mean_values = {}\n",
    "\n",
    "    for d in perf_data:\n",
    "        for key, value in d.items():\n",
    "            if key not in mean_values:\n",
    "                mean_values[key] = []\n",
    "            mean_values[key].append(value)\n",
    "        \n",
    "    nice_names = {\n",
    "        'accuracy': 'Accuracy (%)',\n",
    "        'fm': 'F-measure',\n",
    "        'mcc': 'Matthews Correlation Coefficient',\n",
    "        'psnr': 'Peak Signal-to-Noise Ratio (PSNR)',\n",
    "        'nrm': 'Normalized Root Mean Square Error (NRM)',\n",
    "        'drdm': 'Distance-based Performance Measure (DRDM)'\n",
    "    }\n",
    "\n",
    "    mean_values_single = {nice_names[key]: round(value[0], 2) for key, value in mean_values.items()}\n",
    "    \n",
    "    if(print_results == True):\n",
    "        data = [\n",
    "            [\"Metric\", \"Processed Images\"],\n",
    "            [\"Accuracy (%)\", \"{:.2f}\".format(mean_values_single['accuracy'])],\n",
    "            [\"F-measure\", \"{:.2f}\".format(mean_values_single['fm'])],\n",
    "            [\"Matthews Correlation Coefficient\", \"{:.2f}\".format(mean_values_single['mcc'])],\n",
    "            [\"Peak Signal-to-Noise Ratio (PSNR)\", \"{:.2f}\".format(mean_values_single['psnr'])],\n",
    "            [\"Normalized Root Mean Square Error (NRM)\", \"{:.2f}\".format(mean_values_single['nrm'])],\n",
    "            [\"Distance-based Performance Measure (DRDM)\", \"{:.2f}\".format(mean_values_single['drdm'])],\n",
    "        ]\n",
    "\n",
    "        print(tabulate(data, headers=\"firstrow\", tablefmt=\"grid\"))\n",
    "\n",
    "    return mean_values_single\n",
    "\n",
    "def show_metrics_table(metrics_dicts):\n",
    "    metrics_names = list(metrics_dicts.values())[0].keys()\n",
    "\n",
    "    headers = [\"Metric\"] + list(metrics_dicts.keys())\n",
    "\n",
    "    table_data = []\n",
    "\n",
    "    for metric_name in metrics_names:\n",
    "        row_data = [metric_name]\n",
    "        for metrics_dict in metrics_dicts.values():\n",
    "            row_data.append(\"{:.2f}\".format(metrics_dict[metric_name]))\n",
    "        table_data.append(row_data)\n",
    "\n",
    "    print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))"
   ],
   "id": "2aae19578254d820",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T20:30:43.604071Z",
     "start_time": "2024-04-24T20:30:43.599177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "def evaluate(gt_imgs, pr_imgs, print_results=True):\n",
    "    perf_data = []\n",
    "\n",
    "    # Calculate performance for each ground truth and predicted image pair\n",
    "    for gt_img, pr_img in zip(gt_imgs, pr_imgs):\n",
    "        perf_data.append(doxapy.calculate_performance(gt_img, pr_img))\n",
    "\n",
    "    mean_values = {}\n",
    "\n",
    "    # Aggregate values for each metric across all image comparisons\n",
    "    for d in perf_data:\n",
    "        for key, value in d.items():\n",
    "            if key not in mean_values:\n",
    "                mean_values[key] = []\n",
    "            mean_values[key].append(value)\n",
    "        \n",
    "    # Prepare nicer names for the metrics to display\n",
    "    nice_names = {\n",
    "        'accuracy': 'Accuracy (%)',\n",
    "        'fm': 'F-measure',\n",
    "        'mcc': 'Matthews Correlation Coefficient',\n",
    "        'psnr': 'Peak Signal-to-Noise Ratio (PSNR)',\n",
    "        'nrm': 'Normalized Root Mean Square Error (NRM)',\n",
    "        'drdm': 'Distance-based Performance Measure (DRDM)'\n",
    "    }\n",
    "\n",
    "    # Prepare a dictionary with the average values for each metric, if present\n",
    "    mean_values_single = {}\n",
    "    for key, values in mean_values.items():\n",
    "        if key in nice_names:\n",
    "            mean_values_single[nice_names[key]] = round(sum(values) / len(values), 2)\n",
    "\n",
    "    # Print results if specified\n",
    "    if print_results:\n",
    "        data = [[\"Metric\", \"Processed Images\"]]\n",
    "        for metric_name, metric_value in mean_values_single.items():\n",
    "            data.append([metric_name, \"{:.2f}\".format(metric_value)])\n",
    "\n",
    "        print(tabulate(data, headers=\"firstrow\", tablefmt=\"grid\"))\n",
    "\n",
    "    return mean_values_single"
   ],
   "id": "b83063c86c3db6ad",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T20:35:15.172672Z",
     "start_time": "2024-04-24T20:35:15.120981Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "# from assignment_1.binarization.evaluation import evaluate\n",
    "img1 = 'data/out/dibco1.png'\n",
    "img2 = 'data/out/dibco2.png'\n",
    "img3 = 'data/out/dibco3.png'\n",
    "img4 = 'data/out/dibco4.png'\n",
    "img5 = 'data/out/dibco5.png'\n",
    "\n",
    "gt1 = \"data/davu2024/DIBC02009/dibco_img0001_gt.tif\"\n",
    "gt2 = \"data/davu2024/DIBC02009/dibco_img0002_gt.tif\"\n",
    "gt3 = \"data/davu2024/DIBC02009/dibco_img0003_gt.tif\"\n",
    "gt4 = \"data/davu2024/DIBC02009/dibco_img0004_gt.tif\"\n",
    "gt5 = \"data/davu2024/DIBC02009/dibco_img0005_gt.tif\"\n",
    "\n",
    "gt_imgs = [cv2.imread(gt1, cv2.IMREAD_GRAYSCALE), cv2.imread(gt2, cv2.IMREAD_GRAYSCALE), cv2.imread(gt3, cv2.IMREAD_GRAYSCALE), cv2.imread(gt4, cv2.IMREAD_GRAYSCALE), cv2.imread(gt5, cv2.IMREAD_GRAYSCALE)]\n",
    "\n",
    "pr_imgs = [cv2.imread(img1, cv2.IMREAD_GRAYSCALE), cv2.imread(img2, cv2.IMREAD_GRAYSCALE), cv2.imread(img3, cv2.IMREAD_GRAYSCALE), cv2.imread(img4, cv2.IMREAD_GRAYSCALE), cv2.imread(img5, cv2.IMREAD_GRAYSCALE)]\n",
    "\n",
    "evaluate(gt_imgs, pr_imgs, print_results=True)"
   ],
   "id": "1541f2fe60a7b48c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------+--------------------+\n",
      "| Metric                                    |   Processed Images |\n",
      "+===========================================+====================+\n",
      "| Accuracy (%)                              |              96.78 |\n",
      "+-------------------------------------------+--------------------+\n",
      "| F-measure                                 |              62.9  |\n",
      "+-------------------------------------------+--------------------+\n",
      "| Matthews Correlation Coefficient          |               0.66 |\n",
      "+-------------------------------------------+--------------------+\n",
      "| Peak Signal-to-Noise Ratio (PSNR)         |              15.83 |\n",
      "+-------------------------------------------+--------------------+\n",
      "| Normalized Root Mean Square Error (NRM)   |               0.24 |\n",
      "+-------------------------------------------+--------------------+\n",
      "| Distance-based Performance Measure (DRDM) |               9.94 |\n",
      "+-------------------------------------------+--------------------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy (%)': 96.78,\n",
       " 'F-measure': 62.9,\n",
       " 'Matthews Correlation Coefficient': 0.66,\n",
       " 'Peak Signal-to-Noise Ratio (PSNR)': 15.83,\n",
       " 'Normalized Root Mean Square Error (NRM)': 0.24,\n",
       " 'Distance-based Performance Measure (DRDM)': 9.94}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1fa5b91daf9762ca"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
